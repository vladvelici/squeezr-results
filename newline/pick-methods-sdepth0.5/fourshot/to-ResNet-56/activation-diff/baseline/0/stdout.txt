start iteration 0
[activation diff]: block to remove picked: 1, with score 0.004102. All blocks and scores: [(1, 0.004101692233234644), (30, 0.007408220262732357), (2, 0.007985776232089847), (31, 0.009389899671077728), (34, 0.010470235371030867), (33, 0.01066080154851079), (35, 0.010738129378296435), (32, 0.011000205995514989), (28, 0.012136681587435305), (29, 0.012968535535037518), (26, 0.013386649778112769), (25, 0.014852561871521175), (24, 0.0158374544698745), (27, 0.01584144728258252), (22, 0.015850531635805964), (23, 0.017256746301427484), (39, 0.019865032751113176), (42, 0.020374012179672718), (38, 0.020783300045877695), (43, 0.021396999713033438), (14, 0.021543872309848666), (41, 0.021867160219699144), (5, 0.022075895918533206), (44, 0.02268001763150096), (45, 0.02354323328472674), (40, 0.023729902459308505), (47, 0.02458315109834075), (49, 0.024717332795262337), (37, 0.02491862652823329), (50, 0.025328058283776045), (3, 0.02548178262077272), (21, 0.025725116720423102), (20, 0.027015636209398508), (46, 0.02847206825390458), (17, 0.029906653333455324), (51, 0.030538042075932026), (48, 0.03126738406717777), (19, 0.03464338416233659), (16, 0.045143814757466316), (15, 0.04644394526258111), (0, 0.047015932854264975), (6, 0.0505386870354414), (7, 0.05062374472618103), (4, 0.05095723830163479), (10, 0.0635546650737524), (13, 0.06386727746576071), (8, 0.06656634947285056), (52, 0.06687119510024786), (12, 0.07278608530759811), (11, 0.07457803376019001), (9, 0.07985101919621229), (36, 0.3381783664226532), (18, 0.4791155532002449), (53, 0.8781041875481606)]
computing accuracy for after removing block 1 . block score: 0.004101692233234644
removed block 1 current accuracy 0.9526 loss from initial  0.0016000000000000458
since last training loss: 0.0016000000000000458 threshold 999.0 training needed False
start iteration 1
[activation diff]: block to remove picked: 30, with score 0.007432. All blocks and scores: [(30, 0.0074322286527603865), (2, 0.00826211943058297), (31, 0.00935603550169617), (34, 0.01041069463826716), (33, 0.010654617100954056), (35, 0.01074785809032619), (32, 0.010959888575598598), (28, 0.012139415019191802), (29, 0.013024119660258293), (26, 0.013423070777207613), (25, 0.014838967355899513), (24, 0.015840050531551242), (22, 0.015861989930272102), (27, 0.01593584311194718), (23, 0.0171973102260381), (39, 0.019810708006843925), (42, 0.0203757849521935), (38, 0.020699690328910947), (43, 0.021354888333007693), (14, 0.021494800224900246), (5, 0.02160203969106078), (41, 0.021836188388988376), (44, 0.022733140038326383), (45, 0.02350816805846989), (40, 0.023767677834257483), (47, 0.024559472920373082), (49, 0.02471844246610999), (37, 0.024910897249355912), (50, 0.025358065031468868), (21, 0.02565345703624189), (3, 0.026047389954328537), (20, 0.026917600305750966), (46, 0.028486902127042413), (17, 0.02997702592983842), (51, 0.030507692601531744), (48, 0.03125940286554396), (19, 0.03456938127055764), (16, 0.04483657795935869), (15, 0.04618541803210974), (0, 0.04701593331992626), (4, 0.05096400436013937), (7, 0.05149598652496934), (6, 0.05149898258969188), (10, 0.06320085097104311), (13, 0.0641240868717432), (52, 0.0667257159948349), (8, 0.06816731486469507), (12, 0.07305373623967171), (11, 0.07487673219293356), (9, 0.0809960039332509), (36, 0.3380008935928345), (18, 0.4791026674211025), (53, 0.8785938993096352)]
computing accuracy for after removing block 30 . block score: 0.0074322286527603865
removed block 30 current accuracy 0.9512 loss from initial  0.0030000000000000027
since last training loss: 0.0030000000000000027 threshold 999.0 training needed False
start iteration 2
[activation diff]: block to remove picked: 2, with score 0.008262. All blocks and scores: [(2, 0.008262119081337005), (31, 0.009376280126161873), (34, 0.010059620952233672), (35, 0.01036423770710826), (33, 0.01087033748626709), (32, 0.011195369763299823), (28, 0.012139414669945836), (29, 0.01302411942742765), (26, 0.013423070311546326), (25, 0.014838967588730156), (24, 0.015840050298720598), (22, 0.01586198969744146), (27, 0.015935842879116535), (23, 0.017197310458868742), (39, 0.019759316463023424), (42, 0.02024901262484491), (38, 0.020374777959659696), (14, 0.021494801621884108), (43, 0.02155957417562604), (5, 0.02160203969106078), (41, 0.021747957915067673), (44, 0.022674295352771878), (45, 0.023344096960499883), (40, 0.02429918060079217), (49, 0.024541822029277682), (47, 0.02454807865433395), (50, 0.025325311115011573), (37, 0.025393128860741854), (21, 0.02565345703624189), (3, 0.02604739088565111), (20, 0.026917600771412253), (46, 0.02829100680537522), (17, 0.029977025697007775), (51, 0.030124979093670845), (48, 0.03119896212592721), (19, 0.03456938127055764), (16, 0.04483657795935869), (15, 0.04618541989475489), (0, 0.047015932854264975), (4, 0.05096400249749422), (7, 0.05149598699063063), (6, 0.051498983055353165), (10, 0.0632008514367044), (13, 0.0641240868717432), (52, 0.06627211719751358), (8, 0.0681673139333725), (12, 0.07305373437702656), (11, 0.07487673126161098), (9, 0.08099600300192833), (36, 0.3413781188428402), (18, 0.4791026636958122), (53, 0.8824182897806168)]
computing accuracy for after removing block 2 . block score: 0.008262119081337005
removed block 2 current accuracy 0.9514 loss from initial  0.0028000000000000247
since last training loss: 0.0028000000000000247 threshold 999.0 training needed False
start iteration 3
[activation diff]: block to remove picked: 31, with score 0.009362. All blocks and scores: [(31, 0.009361536125652492), (34, 0.010238023940473795), (35, 0.010466494015417993), (33, 0.01087710028514266), (32, 0.011164091643877327), (28, 0.012178285629488528), (29, 0.013285146676935256), (26, 0.01352362206671387), (25, 0.01487452199216932), (24, 0.01594328531064093), (22, 0.01595701789483428), (27, 0.016130100470036268), (23, 0.017130023101344705), (39, 0.019766291603446007), (42, 0.020299390191212296), (38, 0.020503100706264377), (5, 0.021341981133446097), (14, 0.02134819608181715), (43, 0.02151171094737947), (41, 0.021695787785574794), (44, 0.022763897897675633), (45, 0.02330438233911991), (40, 0.024432898266240954), (47, 0.02448333823122084), (49, 0.024506048299372196), (50, 0.02529494185000658), (37, 0.025467634201049805), (21, 0.02557990374043584), (3, 0.0263768641743809), (20, 0.026921454584226012), (46, 0.028195163933560252), (17, 0.030010283226147294), (51, 0.030042283469811082), (48, 0.031111396849155426), (19, 0.03449071850627661), (16, 0.044537138659507036), (15, 0.045965935569256544), (0, 0.047015934251248837), (4, 0.05099501321092248), (7, 0.05240898905321956), (6, 0.05335415946319699), (10, 0.06339700659736991), (13, 0.06404246017336845), (52, 0.06586655415594578), (8, 0.07122138235718012), (12, 0.07306321896612644), (11, 0.07457236293703318), (9, 0.08245476428419352), (36, 0.3425377272069454), (18, 0.4823562875390053), (53, 0.8822789788246155)]
computing accuracy for after removing block 31 . block score: 0.009361536125652492
removed block 31 current accuracy 0.9476 loss from initial  0.00660000000000005
since last training loss: 0.00660000000000005 threshold 999.0 training needed False
start iteration 4
[activation diff]: block to remove picked: 34, with score 0.009977. All blocks and scores: [(34, 0.009976500878110528), (35, 0.010385191417299211), (33, 0.010895242332480848), (32, 0.01119720481801778), (28, 0.01217828574590385), (29, 0.013285146444104612), (26, 0.013523622299544513), (25, 0.014874521526508033), (24, 0.01594328531064093), (22, 0.015957018127664924), (27, 0.016130101401358843), (23, 0.01713002286851406), (39, 0.0197064271196723), (38, 0.020107181509956717), (42, 0.020161502296105027), (5, 0.02134198136627674), (14, 0.02134819608181715), (43, 0.021484600147232413), (41, 0.021608432522043586), (44, 0.022720722015947104), (45, 0.023412685375660658), (47, 0.024445829447358847), (49, 0.02451933198608458), (40, 0.024599635507911444), (37, 0.025447735097259283), (50, 0.025459976168349385), (21, 0.02557990374043584), (3, 0.02637686487287283), (20, 0.026921454118564725), (46, 0.028387808008119464), (17, 0.030010283924639225), (51, 0.030145179014652967), (48, 0.031237341463565826), (19, 0.034490718971937895), (16, 0.044537138659507036), (15, 0.04596593417227268), (0, 0.04701593238860369), (4, 0.05099501274526119), (7, 0.052408990915864706), (6, 0.05335415853187442), (10, 0.06339700659736991), (13, 0.06404245924204588), (52, 0.06588033400475979), (8, 0.0712213832885027), (12, 0.07306321989744902), (11, 0.07457236386835575), (9, 0.08245476335287094), (36, 0.34473611786961555), (18, 0.4823562949895859), (53, 0.8889129683375359)]
computing accuracy for after removing block 34 . block score: 0.009976500878110528
removed block 34 current accuracy 0.9438 loss from initial  0.010400000000000076
since last training loss: 0.010400000000000076 threshold 999.0 training needed False
start iteration 5
[activation diff]: block to remove picked: 35, with score 0.010432. All blocks and scores: [(35, 0.010432198992930353), (33, 0.010895242332480848), (32, 0.011197204701602459), (28, 0.012178285513073206), (29, 0.013285147375427186), (26, 0.01352362206671387), (25, 0.014874521875753999), (24, 0.015943285077810287), (22, 0.01595701859332621), (27, 0.0161301011685282), (23, 0.017130023101344705), (38, 0.019098805030807853), (39, 0.019185196375474334), (42, 0.019289989722892642), (41, 0.020917906193062663), (43, 0.020933943334966898), (5, 0.02134198066778481), (14, 0.02134819538332522), (44, 0.02214460470713675), (45, 0.023251495324075222), (47, 0.02415113407187164), (49, 0.024187197908759117), (40, 0.02430111332796514), (37, 0.02487713727168739), (50, 0.025220378767699003), (21, 0.02557990327477455), (3, 0.0263768641743809), (20, 0.02692145435139537), (46, 0.027900271117687225), (51, 0.029545043129473925), (17, 0.03001028299331665), (48, 0.03086567111313343), (19, 0.03449071804061532), (16, 0.0445371400564909), (15, 0.04596593510359526), (0, 0.047015932854264975), (4, 0.05099501274526119), (7, 0.05240898858755827), (6, 0.05335416039451957), (10, 0.06339700752869248), (13, 0.0640424583107233), (52, 0.06501816306263208), (8, 0.07122138235718012), (12, 0.07306321896612644), (11, 0.07457236386835575), (9, 0.08245476428419352), (36, 0.34162065759301186), (18, 0.4823562651872635), (53, 0.9064874947071075)]
computing accuracy for after removing block 35 . block score: 0.010432198992930353
removed block 35 current accuracy 0.943 loss from initial  0.011200000000000099
training start
training epoch 0 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best True lr [0.001]
training epoch 1 val accuracy 0.9448 topk_dict {'top1': 0.9448} is_best False lr [0.001]
training epoch 2 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 3 val accuracy 0.9462 topk_dict {'top1': 0.9462} is_best False lr [0.001]
training epoch 4 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 5 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 6 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 7 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 8 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 9 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 10 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.001]
training epoch 11 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 12 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 13 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 14 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 15 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 16 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 17 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 18 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 19 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 20 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 21 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 22 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best True lr [0.001]
training epoch 23 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 24 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 25 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 26 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 27 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 28 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 29 val accuracy 0.9536 topk_dict {'top1': 0.9536} is_best False lr [0.001]
training epoch 30 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 31 val accuracy 0.954 topk_dict {'top1': 0.954} is_best True lr [0.001]
training epoch 32 val accuracy 0.9534 topk_dict {'top1': 0.9534} is_best False lr [0.001]
training epoch 33 val accuracy 0.9548 topk_dict {'top1': 0.9548} is_best True lr [0.001]
training epoch 34 val accuracy 0.9546 topk_dict {'top1': 0.9546} is_best False lr [0.001]
training epoch 35 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 36 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 37 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best False lr [0.001]
training epoch 38 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 39 val accuracy 0.9526 topk_dict {'top1': 0.9526} is_best False lr [0.001]
training epoch 40 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 41 val accuracy 0.953 topk_dict {'top1': 0.953} is_best False lr [0.001]
training epoch 42 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 43 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 44 val accuracy 0.9538 topk_dict {'top1': 0.9538} is_best False lr [0.001]
training epoch 45 val accuracy 0.9544 topk_dict {'top1': 0.9544} is_best False lr [0.001]
training epoch 46 val accuracy 0.9532 topk_dict {'top1': 0.9532} is_best False lr [0.001]
training epoch 47 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 48 val accuracy 0.954 topk_dict {'top1': 0.954} is_best False lr [0.001]
training epoch 49 val accuracy 0.9528 topk_dict {'top1': 0.9528} is_best False lr [0.001]
loading model_best from epoch 33 (acc 0.954800)
finished training. finished 50 epochs. accuracy 0.9548 topk_dict {'top1': 0.9548}
start iteration 6
[activation diff]: block to remove picked: 26, with score 0.008501. All blocks and scores: [(26, 0.008501055533997715), (32, 0.00948949228040874), (28, 0.009497618884779513), (25, 0.009636647766456008), (29, 0.009716676780954003), (22, 0.010057862265966833), (33, 0.010224846540950239), (23, 0.011151373852044344), (24, 0.011152981431223452), (27, 0.01132456841878593), (21, 0.012323888717219234), (38, 0.013994840905070305), (40, 0.014046581811271608), (3, 0.014451906317844987), (42, 0.014553906745277345), (20, 0.01460726757068187), (41, 0.01517035358119756), (39, 0.015580267296172678), (43, 0.015701908501796424), (5, 0.015959598822519183), (37, 0.01637297123670578), (44, 0.016790052643045783), (14, 0.017737715737894177), (19, 0.018687562784180045), (17, 0.019239229150116444), (0, 0.02015493903309107), (45, 0.020343624986708164), (46, 0.021625893656164408), (47, 0.022533689392730594), (6, 0.026370125822722912), (15, 0.026845832588151097), (49, 0.028722094371914864), (4, 0.0292224430013448), (16, 0.030355886789038777), (7, 0.030475490493699908), (48, 0.032864135690033436), (50, 0.034707887563854456), (13, 0.03532282169908285), (10, 0.037277232855558395), (8, 0.04096778156235814), (11, 0.041074613109230995), (12, 0.04120106529444456), (9, 0.048491260036826134), (51, 0.05499151302501559), (52, 0.10212280508130789), (36, 0.17936553061008453), (18, 0.26073889061808586), (53, 0.6351827383041382)]
computing accuracy for after removing block 26 . block score: 0.008501055533997715
removed block 26 current accuracy 0.9508 loss from initial  0.0034000000000000696
since last training loss: 0.0040000000000000036 threshold 999.0 training needed False
start iteration 7
[activation diff]: block to remove picked: 28, with score 0.009162. All blocks and scores: [(28, 0.009162486880086362), (32, 0.009288551635108888), (25, 0.009636647999286652), (29, 0.00967200833838433), (22, 0.010057862382382154), (33, 0.010134546435438097), (23, 0.011151374084874988), (24, 0.011152981780469418), (27, 0.011492704041302204), (21, 0.012323888717219234), (38, 0.013745531789027154), (40, 0.013877937570214272), (42, 0.014091511373408139), (3, 0.014451906317844987), (20, 0.014607267454266548), (41, 0.015029336209408939), (39, 0.015344548504799604), (43, 0.015443436917848885), (5, 0.01595959928818047), (37, 0.016166559187695384), (44, 0.01650638971477747), (14, 0.01773771527223289), (19, 0.018687563948333263), (17, 0.019239229150116444), (45, 0.019994793459773064), (0, 0.020154939498752356), (46, 0.02132302289828658), (47, 0.022047851467505097), (6, 0.026370125822722912), (15, 0.026845833286643028), (49, 0.028192203026264906), (4, 0.0292224430013448), (16, 0.030355886789038777), (7, 0.030475490493699908), (48, 0.03253356274217367), (50, 0.034612374380230904), (13, 0.03532282216474414), (10, 0.03727723238989711), (8, 0.040967780631035566), (11, 0.041074613109230995), (12, 0.04120106529444456), (9, 0.048491261433809996), (51, 0.05360728269442916), (52, 0.1008180733770132), (36, 0.17657948471605778), (18, 0.26073889434337616), (53, 0.6299743875861168)]
computing accuracy for after removing block 28 . block score: 0.009162486880086362
removed block 28 current accuracy 0.9484 loss from initial  0.005800000000000027
since last training loss: 0.006399999999999961 threshold 999.0 training needed False
start iteration 8
[activation diff]: block to remove picked: 32, with score 0.009091. All blocks and scores: [(32, 0.009090987383387983), (29, 0.009531104587949812), (25, 0.00963664788287133), (33, 0.009759323322214186), (22, 0.010057861916720867), (23, 0.011151374084874988), (24, 0.011152981780469418), (27, 0.011492703692056239), (21, 0.012323888717219234), (38, 0.013232992612756789), (42, 0.013292640098370612), (40, 0.013350310735404491), (3, 0.014451906317844987), (41, 0.014486594125628471), (20, 0.014607267919927835), (43, 0.014805514016188681), (39, 0.015010583912953734), (37, 0.015695877838879824), (5, 0.015959598822519183), (44, 0.015989569947123528), (14, 0.017737715505063534), (19, 0.018687562784180045), (17, 0.019239229382947087), (45, 0.019442291697487235), (0, 0.020154939498752356), (46, 0.020587853156030178), (47, 0.021149713080376387), (6, 0.026370125589892268), (15, 0.026845832355320454), (49, 0.02730574761517346), (4, 0.029222443234175444), (16, 0.030355886789038777), (7, 0.030475490260869265), (48, 0.03150778263807297), (50, 0.03354594670236111), (13, 0.03532282216474414), (10, 0.037277232855558395), (8, 0.040967780631035566), (11, 0.04107461264356971), (12, 0.04120106576010585), (9, 0.048491259571164846), (51, 0.05149654811248183), (52, 0.09717282559722662), (36, 0.1711329948157072), (18, 0.26073889434337616), (53, 0.6123052388429642)]
computing accuracy for after removing block 32 . block score: 0.009090987383387983
removed block 32 current accuracy 0.9492 loss from initial  0.0050000000000000044
since last training loss: 0.005599999999999938 threshold 999.0 training needed False
start iteration 9
[activation diff]: block to remove picked: 29, with score 0.009531. All blocks and scores: [(29, 0.009531104704365134), (25, 0.009636647650040686), (33, 0.009689271682873368), (22, 0.01005786214955151), (23, 0.01115137420129031), (24, 0.011152981664054096), (27, 0.011492704157717526), (21, 0.012323888950049877), (42, 0.012647331575863063), (38, 0.012852584244683385), (40, 0.013074144255369902), (41, 0.014175185700878501), (43, 0.014442203915677965), (3, 0.014451906317844987), (20, 0.014607267454266548), (39, 0.014643256436102092), (37, 0.015123128425329924), (44, 0.015449700178578496), (5, 0.015959599055349827), (14, 0.017737715737894177), (19, 0.018687562784180045), (45, 0.01900946837849915), (17, 0.019239229382947087), (0, 0.020154939731583), (46, 0.0201591313816607), (47, 0.020432903431355953), (6, 0.026370124891400337), (49, 0.02650412847287953), (15, 0.026845832355320454), (4, 0.02922244230285287), (16, 0.030355885857716203), (7, 0.030475490260869265), (48, 0.03075701044872403), (50, 0.03252113563939929), (13, 0.03532282216474414), (10, 0.03727723332121968), (8, 0.040967781096696854), (11, 0.04107461264356971), (12, 0.04120106529444456), (9, 0.048491259571164846), (51, 0.0498028127476573), (52, 0.09465738944709301), (36, 0.16756771132349968), (18, 0.26073890179395676), (53, 0.6000009551644325)]
computing accuracy for after removing block 29 . block score: 0.009531104704365134
removed block 29 current accuracy 0.9432 loss from initial  0.01100000000000001
since last training loss: 0.011599999999999944 threshold 999.0 training needed False
start iteration 10
[activation diff]: block to remove picked: 33, with score 0.009518. All blocks and scores: [(33, 0.009518223232589662), (25, 0.009636647999286652), (22, 0.010057862033136189), (23, 0.011151374084874988), (24, 0.011152981780469418), (27, 0.011492703924886882), (42, 0.012109952396713197), (38, 0.012312927399761975), (21, 0.012323888367973268), (40, 0.012604426359757781), (41, 0.013741712784394622), (43, 0.014081963920034468), (39, 0.01414496754296124), (3, 0.014451906434260309), (20, 0.014607267454266548), (37, 0.014724561711773276), (44, 0.014885045937262475), (5, 0.01595959858968854), (14, 0.017737715737894177), (45, 0.018522951286286116), (19, 0.01868756301701069), (17, 0.0192392289172858), (47, 0.019747539656236768), (46, 0.019788811216130853), (0, 0.020154939731583), (49, 0.025590226287022233), (6, 0.026370125822722912), (15, 0.026845832355320454), (4, 0.029222442768514156), (48, 0.03031615843065083), (16, 0.030355885857716203), (7, 0.030475490959361196), (50, 0.03163711982779205), (13, 0.035322822630405426), (10, 0.03727723332121968), (8, 0.04096778156235814), (11, 0.04107461264356971), (12, 0.041201064828783274), (51, 0.04806162463501096), (9, 0.04849125910550356), (52, 0.09192787669599056), (36, 0.16401328891515732), (18, 0.26073889806866646), (53, 0.5914497002959251)]
computing accuracy for after removing block 33 . block score: 0.009518223232589662
removed block 33 current accuracy 0.9424 loss from initial  0.011800000000000033
since last training loss: 0.012399999999999967 threshold 999.0 training needed False
start iteration 11
[activation diff]: block to remove picked: 25, with score 0.009637. All blocks and scores: [(25, 0.00963664788287133), (22, 0.01005786214955151), (23, 0.011151373968459666), (24, 0.011152981780469418), (27, 0.011492703924886882), (42, 0.01151990459766239), (38, 0.011823724256828427), (40, 0.012168580549769104), (21, 0.012323888600803912), (41, 0.0132885369239375), (43, 0.01345462235622108), (39, 0.013732415274716914), (37, 0.014282211777754128), (44, 0.014283097581937909), (3, 0.014451906317844987), (20, 0.014607267454266548), (5, 0.01595959858968854), (14, 0.01773771597072482), (45, 0.018200608668848872), (19, 0.01868756301701069), (47, 0.018822407815605402), (46, 0.019173915265128016), (17, 0.0192392289172858), (0, 0.020154939498752356), (49, 0.0246202249545604), (6, 0.026370125822722912), (15, 0.026845832588151097), (48, 0.029006907483562827), (4, 0.0292224430013448), (16, 0.030355886090546846), (7, 0.030475490959361196), (50, 0.030548915965482593), (13, 0.03532282216474414), (10, 0.03727723238989711), (8, 0.040967781096696854), (11, 0.04107461217790842), (12, 0.04120106576010585), (51, 0.04535518540069461), (9, 0.048491259571164846), (52, 0.08772581070661545), (36, 0.1598039362579584), (18, 0.26073890179395676), (53, 0.568803183734417)]
computing accuracy for after removing block 25 . block score: 0.00963664788287133
removed block 25 current accuracy 0.9348 loss from initial  0.019400000000000084
training start
training epoch 0 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best True lr [0.001]
training epoch 1 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 2 val accuracy 0.9472 topk_dict {'top1': 0.9472} is_best False lr [0.001]
training epoch 3 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 4 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 5 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best True lr [0.001]
training epoch 6 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 7 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best True lr [0.001]
training epoch 8 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 9 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 10 val accuracy 0.9444 topk_dict {'top1': 0.9444} is_best False lr [0.001]
training epoch 11 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 12 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 13 val accuracy 0.9502 topk_dict {'top1': 0.9502} is_best False lr [0.001]
training epoch 14 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best True lr [0.001]
training epoch 15 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 16 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 17 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 18 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 19 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 20 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 21 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 22 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 23 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 24 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 25 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 26 val accuracy 0.9522 topk_dict {'top1': 0.9522} is_best False lr [0.001]
training epoch 27 val accuracy 0.953 topk_dict {'top1': 0.953} is_best True lr [0.001]
training epoch 28 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 29 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 30 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 31 val accuracy 0.9516 topk_dict {'top1': 0.9516} is_best False lr [0.001]
training epoch 32 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 33 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 34 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 35 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 36 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 37 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 38 val accuracy 0.9442 topk_dict {'top1': 0.9442} is_best False lr [0.001]
training epoch 39 val accuracy 0.952 topk_dict {'top1': 0.952} is_best False lr [0.001]
training epoch 40 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 41 val accuracy 0.9518 topk_dict {'top1': 0.9518} is_best False lr [0.001]
training epoch 42 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 43 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 44 val accuracy 0.9496 topk_dict {'top1': 0.9496} is_best False lr [0.001]
training epoch 45 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best False lr [0.001]
training epoch 46 val accuracy 0.9506 topk_dict {'top1': 0.9506} is_best False lr [0.001]
training epoch 47 val accuracy 0.95 topk_dict {'top1': 0.95} is_best False lr [0.001]
training epoch 48 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 49 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
loading model_best from epoch 27 (acc 0.953000)
finished training. finished 50 epochs. accuracy 0.953 topk_dict {'top1': 0.953}
start iteration 12
[activation diff]: block to remove picked: 42, with score 0.013264. All blocks and scores: [(42, 0.013264323584735394), (39, 0.013675132649950683), (38, 0.014710350311361253), (3, 0.014786705723963678), (40, 0.014867581776343286), (41, 0.01526586094405502), (22, 0.016029473626986146), (43, 0.016457259189337492), (37, 0.016478817677125335), (24, 0.016570540610700846), (21, 0.01687037735246122), (23, 0.017043197294697165), (5, 0.017883934546262026), (44, 0.017912135692313313), (14, 0.01904917019419372), (27, 0.019125844351947308), (20, 0.019505470525473356), (45, 0.020180364837870002), (0, 0.020318251568824053), (17, 0.02226379537023604), (19, 0.023538961773738265), (46, 0.023645862704142928), (47, 0.024169771932065487), (6, 0.02705295756459236), (49, 0.030384379671886563), (4, 0.030701152980327606), (16, 0.03108401596546173), (15, 0.03223465057089925), (7, 0.03278981428593397), (48, 0.03349578147754073), (50, 0.0359738003462553), (13, 0.0389723377302289), (10, 0.03942338330671191), (11, 0.04350048629567027), (8, 0.04448575060814619), (12, 0.046648483257740736), (9, 0.05152420839294791), (51, 0.05999936396256089), (52, 0.11235292628407478), (36, 0.193264689296484), (18, 0.2536521591246128), (53, 0.5534760728478432)]
computing accuracy for after removing block 42 . block score: 0.013264323584735394
removed block 42 current accuracy 0.9488 loss from initial  0.005400000000000071
since last training loss: 0.0041999999999999815 threshold 999.0 training needed False
start iteration 13
[activation diff]: block to remove picked: 39, with score 0.013675. All blocks and scores: [(39, 0.013675132649950683), (38, 0.014710350427776575), (3, 0.014786705491133034), (40, 0.014867581543512642), (41, 0.015265860827639699), (22, 0.016029473394155502), (37, 0.016478817677125335), (24, 0.01657054014503956), (43, 0.01686613028869033), (21, 0.016870377818122506), (23, 0.017043197061866522), (44, 0.017506087897345424), (5, 0.017883934546262026), (14, 0.019049170427024364), (27, 0.01912584458477795), (20, 0.019505470292642713), (45, 0.01987729873508215), (0, 0.020318251568824053), (17, 0.022263794904574752), (46, 0.02316260663792491), (47, 0.023243578150868416), (19, 0.023538961773738265), (6, 0.027052957098931074), (49, 0.02882896549999714), (4, 0.03070115251466632), (16, 0.031084014335647225), (48, 0.03184177400544286), (15, 0.032234651036560535), (7, 0.03278981475159526), (50, 0.03364200284704566), (13, 0.038972337264567614), (10, 0.03942338330671191), (11, 0.04350048815831542), (8, 0.0444857501424849), (12, 0.046648483257740736), (9, 0.0515242088586092), (51, 0.055841867346316576), (52, 0.10527633409947157), (36, 0.1932646930217743), (18, 0.2536521703004837), (53, 0.5213743895292282)]
computing accuracy for after removing block 39 . block score: 0.013675132649950683
removed block 39 current accuracy 0.9458 loss from initial  0.008400000000000074
since last training loss: 0.007199999999999984 threshold 999.0 training needed False
start iteration 14
[activation diff]: block to remove picked: 40, with score 0.014399. All blocks and scores: [(40, 0.014398943749256432), (38, 0.01471035007853061), (41, 0.01472609885968268), (3, 0.014786705840379), (22, 0.01602947385981679), (43, 0.016335332533344626), (37, 0.01647881790995598), (24, 0.016570540377870202), (21, 0.016870377585291862), (23, 0.017043197294697165), (44, 0.017076691845431924), (5, 0.01788393477909267), (14, 0.019049170659855008), (27, 0.01912584388628602), (45, 0.019218748435378075), (20, 0.019505469826981425), (0, 0.020318250870332122), (17, 0.022263795603066683), (46, 0.022340860683470964), (47, 0.022382989060133696), (19, 0.023538961773738265), (6, 0.027052957797423005), (49, 0.027508246013894677), (48, 0.030696376226842403), (4, 0.030701152281835675), (16, 0.031084014801308513), (50, 0.03185335686430335), (15, 0.032234651036560535), (7, 0.03278981614857912), (13, 0.03897233819589019), (10, 0.039423382841050625), (11, 0.04350048769265413), (8, 0.04448575107380748), (12, 0.04664848279207945), (9, 0.05152420839294791), (51, 0.05246223695576191), (52, 0.10058866068720818), (36, 0.1932646930217743), (18, 0.2536521665751934), (53, 0.5006120875477791)]
computing accuracy for after removing block 40 . block score: 0.014398943749256432
removed block 40 current accuracy 0.9422 loss from initial  0.01200000000000001
since last training loss: 0.01079999999999992 threshold 999.0 training needed False
start iteration 15
[activation diff]: block to remove picked: 41, with score 0.014410. All blocks and scores: [(41, 0.014409829280339181), (38, 0.014710350311361253), (3, 0.014786705607548356), (22, 0.016029473626986146), (44, 0.016243170714005828), (43, 0.01634105760604143), (37, 0.016478818375617266), (24, 0.01657054014503956), (21, 0.016870377119630575), (23, 0.017043196829035878), (5, 0.017883934546262026), (45, 0.018170716241002083), (14, 0.01904917019419372), (27, 0.019125844119116664), (20, 0.019505470758304), (0, 0.020318251801654696), (47, 0.02093815733678639), (46, 0.021263350965455174), (17, 0.022263795603066683), (19, 0.023538961773738265), (49, 0.025400848127901554), (6, 0.027052957098931074), (48, 0.028959412360563874), (50, 0.02903122454881668), (4, 0.03070115204900503), (16, 0.031084015732631087), (15, 0.0322346524335444), (7, 0.032789813820272684), (13, 0.03897233819589019), (10, 0.03942338423803449), (11, 0.04350048815831542), (8, 0.04448575107380748), (12, 0.04664848372340202), (51, 0.04774518916383386), (9, 0.05152420653030276), (52, 0.09342808835208416), (36, 0.193264689296484), (18, 0.2536521665751934), (53, 0.45985716581344604)]
computing accuracy for after removing block 41 . block score: 0.014409829280339181
removed block 41 current accuracy 0.9338 loss from initial  0.020400000000000085
since last training loss: 0.019199999999999995 threshold 999.0 training needed False
start iteration 16
[activation diff]: block to remove picked: 38, with score 0.014710. All blocks and scores: [(38, 0.014710350311361253), (3, 0.014786705374717712), (44, 0.015900667058303952), (22, 0.016029473626986146), (37, 0.01647881790995598), (43, 0.016556491376832128), (24, 0.016570540610700846), (21, 0.016870377585291862), (23, 0.017043197294697165), (45, 0.017480411333963275), (5, 0.017883934546262026), (14, 0.019049170659855008), (27, 0.019125844817608595), (20, 0.01950547005981207), (47, 0.019780319649726152), (46, 0.020305705722421408), (0, 0.02031825203448534), (17, 0.022263795137405396), (19, 0.023538962472230196), (49, 0.02373815467581153), (50, 0.02668384090065956), (6, 0.027052956400439143), (48, 0.027272110804915428), (4, 0.03070115321315825), (16, 0.031084015499800444), (15, 0.03223465010523796), (7, 0.032789813820272684), (13, 0.038972337264567614), (10, 0.039423382841050625), (51, 0.042763293255120516), (11, 0.04350048955529928), (8, 0.0444857501424849), (12, 0.04664848372340202), (9, 0.05152420839294791), (52, 0.08596575539559126), (36, 0.19326469488441944), (18, 0.2536521703004837), (53, 0.42006827518343925)]
computing accuracy for after removing block 38 . block score: 0.014710350311361253
removed block 38 current accuracy 0.9264 loss from initial  0.027800000000000047
since last training loss: 0.026599999999999957 threshold 999.0 training needed False
start iteration 17
[activation diff]: block to remove picked: 3, with score 0.014787. All blocks and scores: [(3, 0.014786705840379), (44, 0.0149782634107396), (43, 0.015601261053234339), (22, 0.016029473626986146), (45, 0.016398119740188122), (37, 0.016478818142786622), (24, 0.016570540377870202), (21, 0.016870377818122506), (23, 0.017043197294697165), (5, 0.01788393477909267), (47, 0.01863828138448298), (14, 0.019049169961363077), (46, 0.01911256741732359), (27, 0.01912584388628602), (20, 0.019505470525473356), (0, 0.020318251801654696), (49, 0.02198813227005303), (17, 0.02226379606872797), (19, 0.023538962472230196), (50, 0.024422356160357594), (48, 0.02548540523275733), (6, 0.027052956400439143), (4, 0.030701151117682457), (16, 0.031084015034139156), (15, 0.03223465196788311), (7, 0.03278981428593397), (51, 0.03855977673083544), (13, 0.0389723377302289), (10, 0.03942338330671191), (11, 0.04350048862397671), (8, 0.044485751539468765), (12, 0.046648481860756874), (9, 0.0515242088586092), (52, 0.07862311135977507), (36, 0.1932646930217743), (18, 0.2536521777510643), (53, 0.37753675505518913)]
computing accuracy for after removing block 3 . block score: 0.014786705840379
removed block 3 current accuracy 0.923 loss from initial  0.031200000000000006
training start
training epoch 0 val accuracy 0.944 topk_dict {'top1': 0.944} is_best True lr [0.001]
training epoch 1 val accuracy 0.9412 topk_dict {'top1': 0.9412} is_best False lr [0.001]
training epoch 2 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best True lr [0.001]
training epoch 3 val accuracy 0.945 topk_dict {'top1': 0.945} is_best False lr [0.001]
training epoch 4 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best True lr [0.001]
training epoch 5 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best True lr [0.001]
training epoch 6 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 7 val accuracy 0.947 topk_dict {'top1': 0.947} is_best False lr [0.001]
training epoch 8 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best True lr [0.001]
training epoch 9 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 10 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 11 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 12 val accuracy 0.949 topk_dict {'top1': 0.949} is_best True lr [0.001]
training epoch 13 val accuracy 0.9474 topk_dict {'top1': 0.9474} is_best False lr [0.001]
training epoch 14 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 15 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 16 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 17 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 18 val accuracy 0.9454 topk_dict {'top1': 0.9454} is_best False lr [0.001]
training epoch 19 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 20 val accuracy 0.942 topk_dict {'top1': 0.942} is_best False lr [0.001]
training epoch 21 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best True lr [0.001]
training epoch 22 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 23 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
training epoch 24 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 25 val accuracy 0.9494 topk_dict {'top1': 0.9494} is_best True lr [0.001]
training epoch 26 val accuracy 0.9478 topk_dict {'top1': 0.9478} is_best False lr [0.001]
training epoch 27 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 28 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 29 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 30 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 31 val accuracy 0.9514 topk_dict {'top1': 0.9514} is_best True lr [0.001]
training epoch 32 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 33 val accuracy 0.9488 topk_dict {'top1': 0.9488} is_best False lr [0.001]
training epoch 34 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 35 val accuracy 0.9492 topk_dict {'top1': 0.9492} is_best False lr [0.001]
training epoch 36 val accuracy 0.9498 topk_dict {'top1': 0.9498} is_best False lr [0.001]
training epoch 37 val accuracy 0.9464 topk_dict {'top1': 0.9464} is_best False lr [0.001]
training epoch 38 val accuracy 0.9484 topk_dict {'top1': 0.9484} is_best False lr [0.001]
training epoch 39 val accuracy 0.9482 topk_dict {'top1': 0.9482} is_best False lr [0.001]
training epoch 40 val accuracy 0.9486 topk_dict {'top1': 0.9486} is_best False lr [0.001]
training epoch 41 val accuracy 0.9476 topk_dict {'top1': 0.9476} is_best False lr [0.001]
training epoch 42 val accuracy 0.948 topk_dict {'top1': 0.948} is_best False lr [0.001]
training epoch 43 val accuracy 0.951 topk_dict {'top1': 0.951} is_best False lr [0.001]
training epoch 44 val accuracy 0.9512 topk_dict {'top1': 0.9512} is_best False lr [0.001]
training epoch 45 val accuracy 0.9508 topk_dict {'top1': 0.9508} is_best False lr [0.001]
training epoch 46 val accuracy 0.949 topk_dict {'top1': 0.949} is_best False lr [0.001]
training epoch 47 val accuracy 0.9504 topk_dict {'top1': 0.9504} is_best False lr [0.001]
training epoch 48 val accuracy 0.9466 topk_dict {'top1': 0.9466} is_best False lr [0.001]
training epoch 49 val accuracy 0.9468 topk_dict {'top1': 0.9468} is_best False lr [0.001]
loading model_best from epoch 31 (acc 0.951400)
finished training. finished 50 epochs. accuracy 0.9514 topk_dict {'top1': 0.9514}
start iteration 18
[activation diff]: block to remove picked: 22, with score 0.018923. All blocks and scores: [(22, 0.018923441879451275), (5, 0.02131269220262766), (21, 0.021690835477784276), (23, 0.02192051219753921), (24, 0.0222037595231086), (20, 0.0224218787625432), (14, 0.0229320558719337), (0, 0.023944594198837876), (17, 0.024792168056592345), (27, 0.025291013065725565), (43, 0.02530504181049764), (45, 0.025556284934282303), (44, 0.02556163538247347), (47, 0.026063257362693548), (19, 0.027164058992639184), (37, 0.02752115111798048), (6, 0.03046970791183412), (46, 0.030787735944613814), (49, 0.031775341369211674), (4, 0.03457379341125488), (48, 0.034905796870589256), (15, 0.03501842217519879), (7, 0.03686163388192654), (16, 0.03909513587132096), (50, 0.04220509622246027), (10, 0.042359387036412954), (13, 0.045069852378219366), (11, 0.048369161784648895), (8, 0.049676449969410896), (12, 0.05147425178438425), (9, 0.05622309306636453), (51, 0.0743241710588336), (52, 0.13692301511764526), (36, 0.1931552141904831), (18, 0.26993945986032486), (53, 0.6494149416685104)]
computing accuracy for after removing block 22 . block score: 0.018923441879451275
removed block 22 current accuracy 0.9458 loss from initial  0.008400000000000074
since last training loss: 0.005600000000000049 threshold 999.0 training needed False
start iteration 19
[activation diff]: block to remove picked: 23, with score 0.021054. All blocks and scores: [(23, 0.021054435754194856), (5, 0.02131269220262766), (24, 0.021609039045870304), (21, 0.021690835477784276), (20, 0.022421878529712558), (14, 0.022932056337594986), (0, 0.023944594664499164), (45, 0.024199078790843487), (27, 0.024246713146567345), (43, 0.024281676625832915), (47, 0.02428719075396657), (44, 0.02445613080635667), (17, 0.024792168522253633), (37, 0.026245023123919964), (19, 0.027164058526977897), (46, 0.029263202799484134), (49, 0.02964919013902545), (6, 0.030469707679003477), (48, 0.03281648876145482), (4, 0.03457379387691617), (15, 0.03501842217519879), (7, 0.03686163388192654), (16, 0.039095135405659676), (50, 0.04013638524338603), (10, 0.04235938610509038), (13, 0.04506985144689679), (11, 0.04836916225031018), (8, 0.049676449969410896), (12, 0.05147425225004554), (9, 0.05622309306636453), (51, 0.0706805419176817), (52, 0.13359975069761276), (36, 0.1858153808861971), (18, 0.26993946731090546), (53, 0.6298545300960541)]
computing accuracy for after removing block 23 . block score: 0.021054435754194856
removed block 23 current accuracy 0.9408 loss from initial  0.013400000000000079
since last training loss: 0.010600000000000054 threshold 999.0 training needed False
start iteration 20
[activation diff]: block to remove picked: 5, with score 0.021313. All blocks and scores: [(5, 0.021312691969797015), (21, 0.021690835943445563), (24, 0.021833876380696893), (20, 0.022421878529712558), (14, 0.022932056104764342), (47, 0.02309191203676164), (45, 0.023389672162011266), (44, 0.02367055951617658), (27, 0.023689849535003304), (43, 0.023775309789925814), (0, 0.023944592801854014), (17, 0.02479216828942299), (37, 0.025357196340337396), (19, 0.027164058294147253), (46, 0.028003655141219497), (49, 0.02823370904661715), (6, 0.030469707679003477), (48, 0.03181955008767545), (4, 0.03457379434257746), (15, 0.035018421709537506), (7, 0.036861634347587824), (50, 0.03897067857906222), (16, 0.039095135405659676), (10, 0.04235938610509038), (13, 0.04506985191255808), (11, 0.048369161784648895), (8, 0.049676450435072184), (12, 0.051474252715706825), (9, 0.056223091669380665), (51, 0.06747721508145332), (52, 0.12873378954827785), (36, 0.1825018897652626), (18, 0.26993945613503456), (53, 0.6133415997028351)]
computing accuracy for after removing block 5 . block score: 0.021312691969797015
removed block 5 current accuracy 0.9394 loss from initial  0.014800000000000035
since last training loss: 0.01200000000000001 threshold 999.0 training needed False
start iteration 21
[activation diff]: block to remove picked: 21, with score 0.021333. All blocks and scores: [(21, 0.021332613425329328), (24, 0.021646768087521195), (14, 0.02199766389094293), (20, 0.022153099067509174), (47, 0.023192556109279394), (45, 0.023640335770323873), (27, 0.02393567329272628), (0, 0.02394459373317659), (44, 0.024043048499152064), (43, 0.024065403966233134), (17, 0.024444895796477795), (37, 0.026428557699546218), (19, 0.02678501047194004), (46, 0.028260968392714858), (49, 0.028269395232200623), (6, 0.02977284975349903), (48, 0.03217668132856488), (4, 0.03457379341125488), (15, 0.03464577905833721), (16, 0.037704010028392076), (50, 0.0386986224912107), (7, 0.04149312945082784), (10, 0.04329244699329138), (13, 0.04411224275827408), (11, 0.04593839542940259), (12, 0.04988336190581322), (8, 0.0533182630315423), (9, 0.05587950628250837), (51, 0.06761869136244059), (52, 0.1285320669412613), (36, 0.18552800454199314), (18, 0.27174823358654976), (53, 0.6192550659179688)]
computing accuracy for after removing block 21 . block score: 0.021332613425329328
removed block 21 current accuracy 0.9308 loss from initial  0.023400000000000087
since last training loss: 0.020600000000000063 threshold 999.0 training needed False
start iteration 22
[activation diff]: block to remove picked: 24, with score 0.020168. All blocks and scores: [(24, 0.020167734939604998), (47, 0.021527602337300777), (14, 0.02199766435660422), (20, 0.02215309883467853), (45, 0.022717443527653813), (27, 0.022990745957940817), (43, 0.023096140008419752), (44, 0.02314105164259672), (0, 0.02394459373317659), (17, 0.02444489602930844), (37, 0.02507768990471959), (49, 0.02675714949145913), (19, 0.02678501117043197), (46, 0.026950307423248887), (6, 0.02977284975349903), (48, 0.030691230902448297), (4, 0.034573792945593596), (15, 0.0346457795239985), (50, 0.037400360219180584), (16, 0.037704010028392076), (7, 0.04149312945082784), (10, 0.043292449321597815), (13, 0.04411224229261279), (11, 0.04593839729204774), (12, 0.04988336283713579), (8, 0.05331826163455844), (9, 0.055879505816847086), (51, 0.06377708399668336), (52, 0.12452750001102686), (36, 0.17862211167812347), (18, 0.27174823731184006), (53, 0.5975828394293785)]
computing accuracy for after removing block 24 . block score: 0.020167734939604998
removed block 24 current accuracy 0.9194 loss from initial  0.03480000000000005
since last training loss: 0.03200000000000003 threshold 999.0 training needed False
start iteration 23
[activation diff]: block to remove picked: 47, with score 0.019834. All blocks and scores: [(47, 0.01983398594893515), (43, 0.021357803605496883), (45, 0.02148291259072721), (44, 0.021646297303959727), (14, 0.02199766435660422), (20, 0.0221530981361866), (27, 0.02270997385494411), (0, 0.023944593500345945), (37, 0.0239468845538795), (17, 0.02444489556364715), (49, 0.02484976127743721), (46, 0.025039330823346972), (19, 0.02678501117043197), (48, 0.02866409788839519), (6, 0.029772849520668387), (4, 0.034573792945593596), (15, 0.034645779989659786), (50, 0.03552419599145651), (16, 0.037704010028392076), (7, 0.04149312851950526), (10, 0.04329244839027524), (13, 0.04411224368959665), (11, 0.04593839589506388), (12, 0.049883362371474504), (8, 0.05331826163455844), (9, 0.0558795053511858), (51, 0.0584966279566288), (52, 0.11747319996356964), (36, 0.17076490633189678), (18, 0.27174823731184006), (53, 0.5727238580584526)]
computing accuracy for after removing block 47 . block score: 0.01983398594893515
removed block 47 current accuracy 0.909 loss from initial  0.04520000000000002
since last training loss: 0.04239999999999999 threshold 999.0 training needed False
start iteration 24
[activation diff]: block to remove picked: 43, with score 0.021358. All blocks and scores: [(43, 0.021357804536819458), (45, 0.021482912823557854), (44, 0.021646297303959727), (14, 0.02199766435660422), (20, 0.022153099766001105), (27, 0.022709974786266685), (49, 0.023691812297329307), (0, 0.02394459513016045), (37, 0.02394688338972628), (17, 0.024444896262139082), (46, 0.025039330357685685), (19, 0.026785010704770684), (48, 0.028434023028239608), (6, 0.029772849520668387), (50, 0.03254909627139568), (4, 0.03457379341125488), (15, 0.034645778592675924), (16, 0.037704010028392076), (7, 0.04149312945082784), (10, 0.04329244792461395), (13, 0.044112245086580515), (11, 0.045938397757709026), (12, 0.04988336144015193), (51, 0.052142009139060974), (8, 0.0533182630315423), (9, 0.05587950628250837), (52, 0.10808434803038836), (36, 0.17076490260660648), (18, 0.27174824103713036), (53, 0.5334069132804871)]
computing accuracy for after removing block 43 . block score: 0.021357804536819458
removed block 43 current accuracy 0.9004 loss from initial  0.05380000000000007
since last training loss: 0.051000000000000045 threshold 999.0 training needed False
start iteration 25
[activation diff]: block to remove picked: 45, with score 0.021031. All blocks and scores: [(45, 0.021031309850513935), (49, 0.021512603387236595), (44, 0.02174955839291215), (14, 0.021997664822265506), (20, 0.02215309953317046), (27, 0.02270997385494411), (0, 0.023944594664499164), (37, 0.023946884088218212), (46, 0.0240671809297055), (17, 0.02444489556364715), (48, 0.026732612634077668), (19, 0.026785011403262615), (50, 0.029188141925260425), (6, 0.029772849986329675), (4, 0.034573792945593596), (15, 0.0346457795239985), (16, 0.03770400956273079), (7, 0.04149312851950526), (10, 0.043292447458952665), (13, 0.04411224415525794), (51, 0.044722835533320904), (11, 0.04593839589506388), (12, 0.04988336097449064), (8, 0.053318263962864876), (9, 0.055879505816847086), (52, 0.09620863199234009), (36, 0.17076490074396133), (18, 0.27174824103713036), (53, 0.4863697439432144)]
computing accuracy for after removing block 45 . block score: 0.021031309850513935
removed block 45 current accuracy 0.8774 loss from initial  0.07680000000000009
since last training loss: 0.07400000000000007 threshold 999.0 training needed False
start iteration 26
[activation diff]: block to remove picked: 49, with score 0.019946. All blocks and scores: [(49, 0.01994567271322012), (44, 0.021749558625742793), (14, 0.021997664589434862), (20, 0.022153099766001105), (27, 0.022709974087774754), (0, 0.023944593500345945), (37, 0.023946884786710143), (17, 0.024444896262139082), (46, 0.02448511659167707), (48, 0.024965554475784302), (19, 0.02678501233458519), (50, 0.026806131936609745), (6, 0.029772849520668387), (4, 0.03457379341125488), (15, 0.0346457795239985), (16, 0.0377040090970695), (51, 0.03884865017607808), (7, 0.041493128053843975), (10, 0.04329244885593653), (13, 0.04411224368959665), (11, 0.045938394498080015), (12, 0.04988336190581322), (8, 0.05331826163455844), (9, 0.0558795053511858), (52, 0.08585596736520529), (36, 0.17076490446925163), (18, 0.27174823731184006), (53, 0.44478804990649223)]
computing accuracy for after removing block 49 . block score: 0.01994567271322012
removed block 49 current accuracy 0.8732 loss from initial  0.08100000000000007
training start
training epoch 0 val accuracy 0.9204 topk_dict {'top1': 0.9204} is_best True lr [0.001]
training epoch 1 val accuracy 0.9284 topk_dict {'top1': 0.9284} is_best True lr [0.001]
training epoch 2 val accuracy 0.928 topk_dict {'top1': 0.928} is_best False lr [0.001]
training epoch 3 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best True lr [0.001]
training epoch 4 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best True lr [0.001]
training epoch 5 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best True lr [0.001]
training epoch 6 val accuracy 0.9324 topk_dict {'top1': 0.9324} is_best False lr [0.001]
training epoch 7 val accuracy 0.9326 topk_dict {'top1': 0.9326} is_best False lr [0.001]
training epoch 8 val accuracy 0.9338 topk_dict {'top1': 0.9338} is_best True lr [0.001]
training epoch 9 val accuracy 0.9344 topk_dict {'top1': 0.9344} is_best True lr [0.001]
training epoch 10 val accuracy 0.9328 topk_dict {'top1': 0.9328} is_best False lr [0.001]
training epoch 11 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 12 val accuracy 0.9334 topk_dict {'top1': 0.9334} is_best False lr [0.001]
training epoch 13 val accuracy 0.935 topk_dict {'top1': 0.935} is_best True lr [0.001]
training epoch 14 val accuracy 0.935 topk_dict {'top1': 0.935} is_best False lr [0.001]
training epoch 15 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best True lr [0.001]
training epoch 16 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 17 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 18 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 19 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 20 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 21 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 22 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 23 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 24 val accuracy 0.9368 topk_dict {'top1': 0.9368} is_best True lr [0.001]
training epoch 25 val accuracy 0.9348 topk_dict {'top1': 0.9348} is_best False lr [0.001]
training epoch 26 val accuracy 0.9372 topk_dict {'top1': 0.9372} is_best True lr [0.001]
training epoch 27 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 28 val accuracy 0.9364 topk_dict {'top1': 0.9364} is_best False lr [0.001]
training epoch 29 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 30 val accuracy 0.9342 topk_dict {'top1': 0.9342} is_best False lr [0.001]
training epoch 31 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 32 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 33 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 34 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 35 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best True lr [0.001]
training epoch 36 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 37 val accuracy 0.9374 topk_dict {'top1': 0.9374} is_best False lr [0.001]
training epoch 38 val accuracy 0.9366 topk_dict {'top1': 0.9366} is_best False lr [0.001]
training epoch 39 val accuracy 0.936 topk_dict {'top1': 0.936} is_best False lr [0.001]
training epoch 40 val accuracy 0.937 topk_dict {'top1': 0.937} is_best False lr [0.001]
training epoch 41 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
training epoch 42 val accuracy 0.9354 topk_dict {'top1': 0.9354} is_best False lr [0.001]
training epoch 43 val accuracy 0.9358 topk_dict {'top1': 0.9358} is_best False lr [0.001]
training epoch 44 val accuracy 0.9378 topk_dict {'top1': 0.9378} is_best True lr [0.001]
training epoch 45 val accuracy 0.9362 topk_dict {'top1': 0.9362} is_best False lr [0.001]
training epoch 46 val accuracy 0.9356 topk_dict {'top1': 0.9356} is_best False lr [0.001]
training epoch 47 val accuracy 0.9386 topk_dict {'top1': 0.9386} is_best True lr [0.001]
training epoch 48 val accuracy 0.9376 topk_dict {'top1': 0.9376} is_best False lr [0.001]
training epoch 49 val accuracy 0.9352 topk_dict {'top1': 0.9352} is_best False lr [0.001]
loading model_best from epoch 47 (acc 0.938600)
finished training. finished 50 epochs. accuracy 0.9386 topk_dict {'top1': 0.9386}
